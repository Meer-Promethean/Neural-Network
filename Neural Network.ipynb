{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d04989b-f6d9-4a56-b127-fbbd456dc7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, num_inputs, activation_function):\n",
    "        self.weights = np.random.randn(num_inputs)  # Shape (num_inputs,)\n",
    "        self.bias = np.random.randn()  # Single bias value\n",
    "        self.activation_function = activation_function\n",
    "    \n",
    "    def activate(self, inputs):\n",
    "        # Matrix multiplication (dot product) for the whole batch\n",
    "        z = np.dot(inputs, self.weights) + self.bias\n",
    "        return self.activation_function(z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e1c6290-09e4-4441-8c48-790366dc0c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, num_neurons, num_inputs_per_neuron, activation_function):\n",
    "        self.neurons = [Neuron(num_inputs_per_neuron, activation_function) for _ in range(num_neurons)]\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Forward pass through each neuron, stacking the outputs\n",
    "        layer_output = np.array([neuron.activate(inputs) for neuron in self.neurons]).T\n",
    "        return layer_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8ff8f04-4426-44cf-be7a-f67ebd11f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "    \n",
    "    def add_layer(self, num_neurons, num_inputs_per_neuron, activation_function):\n",
    "        self.layers.append(Layer(num_neurons, num_inputs_per_neuron, activation_function))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        for layer in self.layers:\n",
    "            inputs = layer.forward(inputs)  # Propagate inputs through the layers\n",
    "        return inputs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "970ab82e-c52c-48ef-9d21-9e92f5e19f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55fac036-41f8-484a-ae22-6ae577fc2bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LossFunction:\n",
    "#     @staticmethod\n",
    "#     def mean_squared_error(y_true, y_pred):\n",
    "#         return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def mean_squared_error_derivative(y_true, y_pred):\n",
    "#         return 2 * (y_pred - y_true) / len(y_true)\n",
    "\n",
    "class LossFunction:\n",
    "    @staticmethod\n",
    "    def mean_squared_error(y_true, y_pred):\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_squared_error_derivative(y_true, y_pred):\n",
    "        if isinstance(y_true, np.ndarray):\n",
    "            return 2 * (y_pred - y_true) / len(y_true)\n",
    "        else:\n",
    "            return 2 * (y_pred - y_true)  # For scalar values, no need to divide by length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1499e0ba-0f51-4482-bd06-88a0f8624d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "class NeuralNetworkWithBackprop(NeuralNetwork):\n",
    "    def backward(self, X, y, learning_rate=0.01):\n",
    "        loss_derivative = LossFunction.mean_squared_error_derivative(y, self.forward(X))\n",
    "\n",
    "        # Backpropagate through layers (this needs to be extended for real use)\n",
    "        for layer in reversed(self.layers):\n",
    "            # Update weights and biases (implement gradient calculation)\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9ebe350-93f5-4f67-8456-7a57a3efbae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, learning_rate=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def update(self, weights, gradients):\n",
    "        return weights - self.learning_rate * gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54c02e39-5408-42d6-8c47-b3fb32382f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, epochs=100, learning_rate=0.01):\n",
    "    optimizer = Optimizer(learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        for X_batch, y_batch in zip(X_train, y_train):\n",
    "            predictions = model.forward(X_batch)\n",
    "            loss = LossFunction.mean_squared_error(y_batch, predictions)\n",
    "\n",
    "            # Backpropagation and weight update\n",
    "            model.backward(X_batch, y_batch, learning_rate)\n",
    "            # Update weights and biases here\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f230732-4782-46b1-b941-354c9b61b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    predictions = model.forward(X_test)\n",
    "    accuracy = np.mean(np.round(predictions) == y_test)\n",
    "    print(f\"Accuracy: {accuracy * 100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed6be3e1-1d4d-421c-a545-4d63a664b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate spiral dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_classes=2, n_informative=2, n_redundant=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a194f7b4-d643-43f0-b21a-fede1e4b7a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 6.219870443352529e-08\n",
      "Epoch 2/100, Loss: 6.219870443352529e-08\n",
      "Epoch 3/100, Loss: 6.219870443352529e-08\n",
      "Epoch 4/100, Loss: 6.219870443352529e-08\n",
      "Epoch 5/100, Loss: 6.219870443352529e-08\n",
      "Epoch 6/100, Loss: 6.219870443352529e-08\n",
      "Epoch 7/100, Loss: 6.219870443352529e-08\n",
      "Epoch 8/100, Loss: 6.219870443352529e-08\n",
      "Epoch 9/100, Loss: 6.219870443352529e-08\n",
      "Epoch 10/100, Loss: 6.219870443352529e-08\n",
      "Epoch 11/100, Loss: 6.219870443352529e-08\n",
      "Epoch 12/100, Loss: 6.219870443352529e-08\n",
      "Epoch 13/100, Loss: 6.219870443352529e-08\n",
      "Epoch 14/100, Loss: 6.219870443352529e-08\n",
      "Epoch 15/100, Loss: 6.219870443352529e-08\n",
      "Epoch 16/100, Loss: 6.219870443352529e-08\n",
      "Epoch 17/100, Loss: 6.219870443352529e-08\n",
      "Epoch 18/100, Loss: 6.219870443352529e-08\n",
      "Epoch 19/100, Loss: 6.219870443352529e-08\n",
      "Epoch 20/100, Loss: 6.219870443352529e-08\n",
      "Epoch 21/100, Loss: 6.219870443352529e-08\n",
      "Epoch 22/100, Loss: 6.219870443352529e-08\n",
      "Epoch 23/100, Loss: 6.219870443352529e-08\n",
      "Epoch 24/100, Loss: 6.219870443352529e-08\n",
      "Epoch 25/100, Loss: 6.219870443352529e-08\n",
      "Epoch 26/100, Loss: 6.219870443352529e-08\n",
      "Epoch 27/100, Loss: 6.219870443352529e-08\n",
      "Epoch 28/100, Loss: 6.219870443352529e-08\n",
      "Epoch 29/100, Loss: 6.219870443352529e-08\n",
      "Epoch 30/100, Loss: 6.219870443352529e-08\n",
      "Epoch 31/100, Loss: 6.219870443352529e-08\n",
      "Epoch 32/100, Loss: 6.219870443352529e-08\n",
      "Epoch 33/100, Loss: 6.219870443352529e-08\n",
      "Epoch 34/100, Loss: 6.219870443352529e-08\n",
      "Epoch 35/100, Loss: 6.219870443352529e-08\n",
      "Epoch 36/100, Loss: 6.219870443352529e-08\n",
      "Epoch 37/100, Loss: 6.219870443352529e-08\n",
      "Epoch 38/100, Loss: 6.219870443352529e-08\n",
      "Epoch 39/100, Loss: 6.219870443352529e-08\n",
      "Epoch 40/100, Loss: 6.219870443352529e-08\n",
      "Epoch 41/100, Loss: 6.219870443352529e-08\n",
      "Epoch 42/100, Loss: 6.219870443352529e-08\n",
      "Epoch 43/100, Loss: 6.219870443352529e-08\n",
      "Epoch 44/100, Loss: 6.219870443352529e-08\n",
      "Epoch 45/100, Loss: 6.219870443352529e-08\n",
      "Epoch 46/100, Loss: 6.219870443352529e-08\n",
      "Epoch 47/100, Loss: 6.219870443352529e-08\n",
      "Epoch 48/100, Loss: 6.219870443352529e-08\n",
      "Epoch 49/100, Loss: 6.219870443352529e-08\n",
      "Epoch 50/100, Loss: 6.219870443352529e-08\n",
      "Epoch 51/100, Loss: 6.219870443352529e-08\n",
      "Epoch 52/100, Loss: 6.219870443352529e-08\n",
      "Epoch 53/100, Loss: 6.219870443352529e-08\n",
      "Epoch 54/100, Loss: 6.219870443352529e-08\n",
      "Epoch 55/100, Loss: 6.219870443352529e-08\n",
      "Epoch 56/100, Loss: 6.219870443352529e-08\n",
      "Epoch 57/100, Loss: 6.219870443352529e-08\n",
      "Epoch 58/100, Loss: 6.219870443352529e-08\n",
      "Epoch 59/100, Loss: 6.219870443352529e-08\n",
      "Epoch 60/100, Loss: 6.219870443352529e-08\n",
      "Epoch 61/100, Loss: 6.219870443352529e-08\n",
      "Epoch 62/100, Loss: 6.219870443352529e-08\n",
      "Epoch 63/100, Loss: 6.219870443352529e-08\n",
      "Epoch 64/100, Loss: 6.219870443352529e-08\n",
      "Epoch 65/100, Loss: 6.219870443352529e-08\n",
      "Epoch 66/100, Loss: 6.219870443352529e-08\n",
      "Epoch 67/100, Loss: 6.219870443352529e-08\n",
      "Epoch 68/100, Loss: 6.219870443352529e-08\n",
      "Epoch 69/100, Loss: 6.219870443352529e-08\n",
      "Epoch 70/100, Loss: 6.219870443352529e-08\n",
      "Epoch 71/100, Loss: 6.219870443352529e-08\n",
      "Epoch 72/100, Loss: 6.219870443352529e-08\n",
      "Epoch 73/100, Loss: 6.219870443352529e-08\n",
      "Epoch 74/100, Loss: 6.219870443352529e-08\n",
      "Epoch 75/100, Loss: 6.219870443352529e-08\n",
      "Epoch 76/100, Loss: 6.219870443352529e-08\n",
      "Epoch 77/100, Loss: 6.219870443352529e-08\n",
      "Epoch 78/100, Loss: 6.219870443352529e-08\n",
      "Epoch 79/100, Loss: 6.219870443352529e-08\n",
      "Epoch 80/100, Loss: 6.219870443352529e-08\n",
      "Epoch 81/100, Loss: 6.219870443352529e-08\n",
      "Epoch 82/100, Loss: 6.219870443352529e-08\n",
      "Epoch 83/100, Loss: 6.219870443352529e-08\n",
      "Epoch 84/100, Loss: 6.219870443352529e-08\n",
      "Epoch 85/100, Loss: 6.219870443352529e-08\n",
      "Epoch 86/100, Loss: 6.219870443352529e-08\n",
      "Epoch 87/100, Loss: 6.219870443352529e-08\n",
      "Epoch 88/100, Loss: 6.219870443352529e-08\n",
      "Epoch 89/100, Loss: 6.219870443352529e-08\n",
      "Epoch 90/100, Loss: 6.219870443352529e-08\n",
      "Epoch 91/100, Loss: 6.219870443352529e-08\n",
      "Epoch 92/100, Loss: 6.219870443352529e-08\n",
      "Epoch 93/100, Loss: 6.219870443352529e-08\n",
      "Epoch 94/100, Loss: 6.219870443352529e-08\n",
      "Epoch 95/100, Loss: 6.219870443352529e-08\n",
      "Epoch 96/100, Loss: 6.219870443352529e-08\n",
      "Epoch 97/100, Loss: 6.219870443352529e-08\n",
      "Epoch 98/100, Loss: 6.219870443352529e-08\n",
      "Epoch 99/100, Loss: 6.219870443352529e-08\n",
      "Epoch 100/100, Loss: 6.219870443352529e-08\n",
      "Accuracy: 52.5%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "nn = NeuralNetworkWithBackprop()\n",
    "\n",
    "# Add layers\n",
    "nn.add_layer(10, 2, relu)  # First layer with 10 neurons and 2 inputs\n",
    "nn.add_layer(1, 10, sigmoid)  # Output layer with 1 neuron\n",
    "\n",
    "# Train the network\n",
    "train(nn, X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate(nn, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79319c1-e41b-4219-a97b-474d0fd4a1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
